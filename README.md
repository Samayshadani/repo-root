# ğŸ” AI-Powered GitHub Action â€“ Skills Security Scanner

## ğŸ“Œ Overview

This project implements an AI-powered GitHub Action that scans markdown files inside a `skills/` folder and detects malicious or unsafe instructions automatically.

The goal is to build a security guardrail that prevents unsafe AI skill files (such as prompt injections or data exfiltration attempts) from being merged into the main branch.

The workflow runs on:

- Push to `main`
- Pull Requests

If HIGH severity malicious content is detected, the workflow fails automatically.

---

## ğŸ§  Problem Statement

In modern AI tooling, skills are structured markdown files that define reusable AI behaviors or instructions.

Because these files may influence agent execution logic, they can become security risks if they contain:

- Prompt injection
- Hidden system override commands
- Data exfiltration attempts
- Jailbreak instructions

This project builds an automated CI-based guardrail system to detect such threats before code is merged.

---

## ğŸ—ï¸ Architecture

Repository Structure:

repo-root/
â”‚
â”œâ”€â”€ .github/workflows/scan-skills.yml
â”œâ”€â”€ skills/
â”‚ â”œâ”€â”€ safe_skill.md
â”‚ â”œâ”€â”€ suspicious_skill.md
â”‚ â””â”€â”€ malicious_skill.md
â”‚
â”œâ”€â”€ scanner/
â”‚ â”œâ”€â”€ scan.py
â”‚ â”œâ”€â”€ cache.json
â”‚ â””â”€â”€ ignore_list.txt
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

---

## âš™ï¸ How It Works

1. GitHub Action triggers on push or pull request.
2. The workflow installs Python and Ollama.
3. The scanner reads all `.md` files inside `skills/`.
4. Each file is sent to a local LLM (via Ollama).
5. The model classifies content into:
   - SAFE
   - LOW
   - HIGH
6. If HIGH severity is detected:
   - The workflow exits with a non-zero code
   - CI fails
   - The PR is blocked

---

## ğŸ¤– AI Model Used

This project uses **Ollama** with the `llama3` model.

Why Ollama?

- No API key required
- No quota limitations
- Fully local and reproducible
- Free to use
- No external billing dependency

This ensures the CI pipeline is self-contained and cost-efficient.

---

## ğŸš¦ Severity Levels

The AI classifies each file into:

### âœ… SAFE
No malicious or suspicious content detected.

### âš ï¸ LOW
Suspicious behavior detected (e.g., instruction override patterns), but not clearly malicious.

The workflow continues.

### âŒ HIGH
Clear malicious intent detected (e.g., data exfiltration, secret leakage, system override).

The workflow fails automatically.

---

## ğŸ”„ Caching

The scanner implements file-hash caching.

- Each fileâ€™s SHA256 hash is stored in `cache.json`
- Unchanged files are skipped during scanning
- Improves performance and reduces unnecessary AI calls

Note: GitHub runners are ephemeral environments. Cache persistence across runs would require GitHub caching mechanisms in production.

---

## ğŸ“ Ignore List

An `ignore_list.txt` file allows safe phrases to be excluded from triggering warnings.

This prevents documentation examples from being flagged as malicious.

---

## ğŸš€ Running Locally

### 1ï¸âƒ£ Install Ollama

Download from:
https://ollama.com/download

Pull model:

---

### 2ï¸âƒ£ Install Python dependencies

---

### 3ï¸âƒ£ Run Scanner

---

## ğŸ”„ GitHub Action Workflow

The workflow is located at:

It runs automatically on:

- Push to main
- Pull requests

If HIGH severity is detected, the workflow fails.

---

## ğŸ¯ Demo Flow

1. Add malicious instruction inside a skill file.
2. Push to repository.
3. GitHub Action runs.
4. Workflow fails due to HIGH severity.
5. Remove malicious content.
6. Push again.
7. Workflow passes.

---

## ğŸ›¡ï¸ Security Design Thinking

This project demonstrates:

- AI-based semantic threat detection (instead of simple regex)
- CI/CD guardrail design
- Severity-based triaging
- Automated security enforcement
- DevSecOps thinking
- Reproducible infrastructure

---

## ğŸ“¹ Demo Video

The demo video explains:

- What skills are
- Security risks
- Architecture design
- Why Ollama was chosen
- Live CI failure example
- Successful remediation

---

## âœ… Evaluation Highlights

âœ” Clean repository structure  
âœ” Automated CI integration  
âœ” AI-based classification  
âœ” Security-first design  
âœ” Observability via logs  
âœ” Production-aware decisions  

---

## ğŸ‘¨â€ğŸ’» Author

Samay
